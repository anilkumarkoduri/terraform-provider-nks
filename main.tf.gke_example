provider "stackpoint" {
  org_id     = ""
  ssh_keyset = ""
}

data "stackpoint_instance_specs" "master-specs" {
  provider_code = "${var.gke_code}"
  node_size     = "${var.gke_master_size}"
}

data "stackpoint_instance_specs" "worker-specs" {
  provider_code = "${var.gke_code}"
  node_size     = "${var.gke_worker_size}"
}

resource "stackpoint_cluster" "terraform-cluster" {
  cluster_name          = "Test Packet Cluster TerraForm"
  provider_code         = "${var.gke_code}"
  provider_keyset       = "${var.gke_keyset}"
  region                = "${var.gke_region}"
  k8s_version           = "${var.gke_k8s_version}"
  startup_master_size   = "${data.stackpoint_instance_specs.master-specs.node_size}"
  startup_worker_count  = 2
  startup_worker_size   = "${data.stackpoint_instance_specs.worker-specs.node_size}"
  rbac_enabled          = true
  dashboard_enabled     = true
  etcd_type             = "classic"
  platform              = "${var.gke_platform}"
  channel               = "stable"
  solutions             = ["helm_tiller"]
}

# GKE handles multi-masters internally, so you cannot add a new master node

#resource "stackpoint_nodepool" "nodepool2" {
#  cluster_id           = "${stackpoint_cluster.terraform-cluster.id}"
#  provider_code        = "${var.gke_code}"
#  platform             = "${var.gke_platform}"
#  worker_count         = 1
#  worker_size          = "${data.stackpoint_instance_specs.worker-specs.node_size}"
#}
